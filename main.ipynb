{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45a01ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kxngh/.local/lib/python3.13/site-packages/seaborn/_statistics.py:32: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.stats import gaussian_kde\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ultralytics import YOLO\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736c97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Setup\n",
    "class Config:\n",
    "    BROADCAST_VIDEO = \"data/broadcast.mp4\"\n",
    "    TACTICAM_VIDEO = \"data/tacticam.mp4\"\n",
    "    MODEL_PATH = \"best.pt\"\n",
    "    MAPPING_JSON = \"mapping.json\"\n",
    "    \n",
    "    FRAME_SKIP = 5  \n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "    IOU_THRESHOLD = 0.4\n",
    "    \n",
    "    # Feature extraction parameters\n",
    "    FEATURE_DIM = 512\n",
    "    TEMPORAL_WINDOW = 10  \n",
    "    \n",
    "    OUTPUT_DIR = Path(\"outputs\")\n",
    "    \n",
    "Config.OUTPUT_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d1db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Custom YOLOv11 model loaded successfully from best.pt\n",
      "Model moved to GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Model classes: ['ball', 'goalkeeper', 'player', 'referee']\n"
     ]
    }
   ],
   "source": [
    "# Loads a custom YOLOv11 model and prepares it for inference on GPU or CPU\n",
    "def load_model():\n",
    "    import torch\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = YOLO(Config.MODEL_PATH)\n",
    "    print(f\"Custom YOLOv11 model loaded successfully from {Config.MODEL_PATH}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.to(device)\n",
    "        print(f\"Model moved to GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU not available, running on CPU\")\n",
    "    \n",
    "    print(f\"Model classes: {list(model.names.values())}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b2a837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: 132 frames, 24.81 FPS, 1920x1080\n",
      "Video info: 201 frames, 24.63 FPS, 1920x1080\n"
     ]
    }
   ],
   "source": [
    "# Loads videos and extracts frames with optional skipping and max frame limit\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Video info: {frame_count} frames, {fps:.2f} FPS, {width}x{height}\")\n",
    "    return cap, {'fps': fps, 'frame_count': frame_count, 'width': width, 'height': height}\n",
    "\n",
    "def extract_frames(cap, max_frames=None, frame_skip=1):\n",
    "    frames = []\n",
    "    frame_indices = []\n",
    "    frame_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        if frame_idx % frame_skip == 0:\n",
    "            frames.append(frame)\n",
    "            frame_indices.append(frame_idx)\n",
    "            \n",
    "        frame_idx += 1\n",
    "        \n",
    "        if max_frames and len(frames) >= max_frames:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    return frames, frame_indices\n",
    "\n",
    "broadcast_cap, broadcast_info = load_video(Config.BROADCAST_VIDEO)\n",
    "tacticam_cap, tacticam_info = load_video(Config.TACTICAM_VIDEO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90a6c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/broadcast.mp4...\n",
      "Processed 15 frames...\n",
      "Completed processing 27 frames, 304 total detections\n",
      "Processing data/tacticam.mp4...\n",
      "Processed 15 frames...\n",
      "Processed 30 frames...\n",
      "Completed processing 41 frames, 904 total detections\n"
     ]
    }
   ],
   "source": [
    "# Detects players in video frames using a YOLO model and processes detections per frame\n",
    "def detect_players(model, frame, conf_threshold=0.3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results = model(frame, conf=conf_threshold, device=device, verbose=False)\n",
    "    \n",
    "    detections = []\n",
    "    player_classes = [1, 2, 3]\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                confidence = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "                \n",
    "                if class_id in player_classes:\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    area = width * height\n",
    "                    \n",
    "                    if width > 10 and height > 20 and area > 300:\n",
    "                        detections.append({\n",
    "                            'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                            'confidence': float(confidence),\n",
    "                            'center': [(x1 + x2) / 2, (y1 + y2) / 2],\n",
    "                            'area': area,\n",
    "                            'class_id': class_id,\n",
    "                            'class_name': model.names[class_id]\n",
    "                        })\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def process_video_detections(model, video_path, frame_skip=3, max_frames=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    detections_by_frame = {}\n",
    "    frame_idx = 0\n",
    "    processed_frames = 0\n",
    "    \n",
    "    print(f\"Processing {video_path}...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or processed_frames >= max_frames:\n",
    "            break\n",
    "        \n",
    "        if frame_idx % frame_skip == 0:\n",
    "            detections = detect_players(model, frame, Config.CONFIDENCE_THRESHOLD)\n",
    "            detections_by_frame[frame_idx] = detections\n",
    "            processed_frames += 1\n",
    "            \n",
    "            if processed_frames % 15 == 0:\n",
    "                print(f\"Processed {processed_frames} frames...\")\n",
    "        \n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "    total_detections = sum(len(dets) for dets in detections_by_frame.values())\n",
    "    print(f\"Completed processing {processed_frames} frames, {total_detections} total detections\")\n",
    "    return detections_by_frame\n",
    "\n",
    "broadcast_detections = process_video_detections(model, Config.BROADCAST_VIDEO, Config.FRAME_SKIP)\n",
    "tacticam_detections = process_video_detections(model, Config.TACTICAM_VIDEO, Config.FRAME_SKIP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c12547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 tracks in broadcast video\n",
      "Found 50 tracks in tacticam video\n"
     ]
    }
   ],
   "source": [
    "# Extracts visual and spatial features and builds player tracks across video frames\n",
    "def extract_visual_features(frame, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    player_crop = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if player_crop.size == 0:\n",
    "        return np.zeros(Config.FEATURE_DIM)\n",
    "    \n",
    "    player_crop = cv2.resize(player_crop, (64, 128))\n",
    "    player_crop = cv2.cvtColor(player_crop, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    hist_features = []\n",
    "    for i in range(3):\n",
    "        hist = cv2.calcHist([player_crop], [i], None, [32], [0, 256])\n",
    "        hist_features.extend(hist.flatten())\n",
    "    \n",
    "    gray = cv2.cvtColor(player_crop, cv2.COLOR_RGB2GRAY)\n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    texture_features = [\n",
    "        np.mean(grad_x), np.std(grad_x),\n",
    "        np.mean(grad_y), np.std(grad_y)\n",
    "    ]\n",
    "    \n",
    "    features = np.array(hist_features + texture_features)\n",
    "    \n",
    "    if len(features) < Config.FEATURE_DIM:\n",
    "        features = np.pad(features, (0, Config.FEATURE_DIM - len(features)))\n",
    "    else:\n",
    "        features = features[:Config.FEATURE_DIM]\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_spatial_features(bbox, frame_shape):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    frame_height, frame_width = frame_shape[:2]\n",
    "    \n",
    "    features = {\n",
    "        'center_x': (x1 + x2) / 2 / frame_width,\n",
    "        'center_y': (y1 + y2) / 2 / frame_height,\n",
    "        'width': (x2 - x1) / frame_width,\n",
    "        'height': (y2 - y1) / frame_height,\n",
    "        'area': ((x2 - x1) * (y2 - y1)) / (frame_width * frame_height),\n",
    "        'aspect_ratio': (x2 - x1) / max(1, (y2 - y1))\n",
    "    }\n",
    "    \n",
    "    return np.array(list(features.values()))\n",
    "\n",
    "def build_player_tracks(detections_by_frame, max_distance=80, max_frame_gap=6, min_track_length=3):\n",
    "    tracks = []\n",
    "    \n",
    "    for frame_idx in sorted(detections_by_frame.keys()):\n",
    "        detections = detections_by_frame[frame_idx]\n",
    "        \n",
    "        for detection in detections:\n",
    "            detection['frame'] = frame_idx\n",
    "            assigned = False\n",
    "            \n",
    "            for track in tracks:\n",
    "                if len(track) > 0:\n",
    "                    last_detection = track[-1]\n",
    "                    \n",
    "                    distance = np.sqrt((detection['center'][0] - last_detection['center'][0])**2 + \n",
    "                                       (detection['center'][1] - last_detection['center'][1])**2)\n",
    "                    \n",
    "                    frame_gap = frame_idx - last_detection['frame']\n",
    "                    \n",
    "                    if (distance < max_distance and \n",
    "                        frame_gap <= max_frame_gap and \n",
    "                        detection.get('class_id') == last_detection.get('class_id')):\n",
    "                        track.append(detection)\n",
    "                        assigned = True\n",
    "                        break\n",
    "            \n",
    "            if not assigned:\n",
    "                tracks.append([detection])\n",
    "    \n",
    "    filtered_tracks = [track for track in tracks if len(track) >= min_track_length]\n",
    "    return filtered_tracks\n",
    "\n",
    "broadcast_tracks = build_player_tracks(broadcast_detections)\n",
    "print(f\"Found {len(broadcast_tracks)} tracks in broadcast video\")\n",
    "\n",
    "tacticam_tracks = build_player_tracks(tacticam_detections)\n",
    "print(f\"Found {len(tacticam_tracks)} tracks in tacticam video\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e108a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RUNNING COMPLETE ENHANCED PLAYER MAPPING PIPELINE\n",
      "============================================================\n",
      "Detecting players in broadcast video...\n",
      "Processing data/broadcast.mp4...\n",
      "Processed 15 frames...\n",
      "Completed processing 27 frames, 304 total detections\n",
      "Detecting players in tacticam video...\n",
      "Processing data/tacticam.mp4...\n",
      "Processed 15 frames...\n",
      "Processed 30 frames...\n",
      "Completed processing 41 frames, 904 total detections\n",
      "Building tracks for broadcast video...\n",
      "Found 19 tracks in broadcast video\n",
      "Building tracks for tacticam video...\n",
      "Found 50 tracks in tacticam video\n",
      "Performing enhanced player mapping...\n",
      "Computing enhanced features for all tracks...\n",
      "Processed 5/19 broadcast tracks\n",
      "Processed 10/19 broadcast tracks\n",
      "Processed 15/19 broadcast tracks\n",
      "Processed 5/50 tacticam tracks\n",
      "Processed 10/50 tacticam tracks\n",
      "Processed 15/50 tacticam tracks\n",
      "Processed 20/50 tacticam tracks\n",
      "Processed 25/50 tacticam tracks\n",
      "Processed 30/50 tacticam tracks\n",
      "Processed 35/50 tacticam tracks\n",
      "Processed 40/50 tacticam tracks\n",
      "Processed 45/50 tacticam tracks\n",
      "Processed 50/50 tacticam tracks\n",
      "Calculating similarity matrix...\n",
      "Applying class-based constraints...\n",
      "Finding optimal assignment...\n",
      "\n",
      "Found 18 player mappings:\n",
      "Player 1: player - B0 -> T6 (similarity: 0.479)\n",
      "Player 2: player - B1 -> T9 (similarity: 0.539)\n",
      "Player 3: player - B2 -> T2 (similarity: 0.318)\n",
      "Player 4: player - B3 -> T8 (similarity: 0.154)\n",
      "Player 5: player - B4 -> T32 (similarity: 0.402)\n",
      "Player 6: player - B5 -> T7 (similarity: 0.173)\n",
      "Player 7: player - B6 -> T22 (similarity: 0.351)\n",
      "Player 8: player - B7 -> T19 (similarity: 0.284)\n",
      "Player 9: referee - B8 -> T21 (similarity: 0.252)\n",
      "Player 10: player - B9 -> T0 (similarity: 0.214)\n",
      "Player 11: referee - B10 -> T25 (similarity: 0.295)\n",
      "Player 12: goalkeeper - B11 -> T27 (similarity: 0.583)\n",
      "Player 13: referee - B12 -> T40 (similarity: 0.313)\n",
      "Player 14: referee - B13 -> T34 (similarity: 0.397)\n",
      "Player 15: player - B14 -> T42 (similarity: 0.328)\n",
      "Player 16: player - B15 -> T4 (similarity: 0.439)\n",
      "Player 17: player - B16 -> T3 (similarity: 0.227)\n",
      "Player 18: player - B17 -> T5 (similarity: 0.348)\n"
     ]
    }
   ],
   "source": [
    "# Performs enhanced multi-video soccer player mapping using visual, spatial, and temporal features\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def detect_soccer_players(model, frame, conf_threshold=0.3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results = model(frame, conf=conf_threshold, device=device, verbose=False)\n",
    "    \n",
    "    detections = []\n",
    "    player_classes = [1, 2, 3]\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                confidence = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "                if class_id in player_classes:\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    area = width * height\n",
    "                    if width > 10 and height > 20 and area > 300:\n",
    "                        detections.append({\n",
    "                            'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                            'confidence': float(confidence),\n",
    "                            'center': [(x1 + x2) / 2, (y1 + y2) / 2],\n",
    "                            'area': area,\n",
    "                            'class_id': class_id,\n",
    "                            'class_name': model.names[class_id],\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "    return detections\n",
    "\n",
    "def process_soccer_video(model, video_path, frame_skip=2, max_frames=200):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    detections_by_frame = {}\n",
    "    frame_idx = 0\n",
    "    processed_frames = 0\n",
    "    print(f\"Processing {video_path} for soccer players...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or processed_frames >= max_frames:\n",
    "            break\n",
    "        if frame_idx % frame_skip == 0:\n",
    "            detections = detect_soccer_players(model, frame, conf_threshold=0.3)\n",
    "            detections_by_frame[frame_idx] = detections\n",
    "            processed_frames += 1\n",
    "            if processed_frames % 20 == 0:\n",
    "                player_count = len(detections)\n",
    "                class_breakdown = {}\n",
    "                for det in detections:\n",
    "                    class_name = det['class_name']\n",
    "                    class_breakdown[class_name] = class_breakdown.get(class_name, 0) + 1\n",
    "                print(f\"Frame {frame_idx}: {player_count} total - {class_breakdown}\")\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    total_detections = sum(len(dets) for dets in detections_by_frame.values())\n",
    "    print(f\"Completed: {processed_frames} frames, {total_detections} total player detections\")\n",
    "    return detections_by_frame\n",
    "\n",
    "def extract_temporal_features(track):\n",
    "    if len(track) < 2:\n",
    "        return np.zeros(8)\n",
    "    positions = np.array([det['center'] for det in track])\n",
    "    frames = np.array([det['frame'] for det in track])\n",
    "    velocities = []\n",
    "    for i in range(1, len(positions)):\n",
    "        dx = positions[i][0] - positions[i-1][0]\n",
    "        dy = positions[i][1] - positions[i-1][1]\n",
    "        dt = frames[i] - frames[i-1]\n",
    "        if dt > 0:\n",
    "            vx = dx / dt\n",
    "            vy = dy / dt\n",
    "            velocities.append([vx, vy])\n",
    "    if not velocities:\n",
    "        return np.zeros(8)\n",
    "    velocities = np.array(velocities)\n",
    "    speed = np.sqrt(velocities[:, 0]**2 + velocities[:, 1]**2)\n",
    "    features = [\n",
    "        np.mean(speed),\n",
    "        np.max(speed),\n",
    "        np.var(speed),\n",
    "        np.mean(velocities[:, 0]),\n",
    "        np.mean(velocities[:, 1]),\n",
    "        frames[-1] - frames[0],\n",
    "        np.sqrt((positions[-1][0] - positions[0][0])**2 + (positions[-1][1] - positions[0][1])**2),\n",
    "        np.var(positions, axis=0).mean()\n",
    "    ]\n",
    "    return np.array(features)\n",
    "\n",
    "def compute_enhanced_track_features(track, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    visual_features = []\n",
    "    spatial_features = []\n",
    "    for detection in track:\n",
    "        frame_idx = detection['frame']\n",
    "        bbox = detection['bbox']\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            vis_feat = extract_visual_features(frame, bbox)\n",
    "            visual_features.append(vis_feat)\n",
    "            spat_feat = extract_spatial_features(bbox, frame.shape)\n",
    "            spatial_features.append(spat_feat)\n",
    "    cap.release()\n",
    "    avg_visual = np.mean(visual_features, axis=0) if visual_features else np.zeros(Config.FEATURE_DIM)\n",
    "    avg_spatial = np.mean(spatial_features, axis=0) if spatial_features else np.zeros(6)\n",
    "    temporal_features = extract_temporal_features(track)\n",
    "    return np.concatenate([avg_visual, avg_spatial, temporal_features])\n",
    "\n",
    "def calculate_similarity_matrix(broadcast_features, tacticam_features):\n",
    "    similarity_matrix = np.zeros((len(broadcast_features), len(tacticam_features)))\n",
    "    scaler = StandardScaler()\n",
    "    if len(broadcast_features) > 0 and len(tacticam_features) > 0:\n",
    "        all_features = broadcast_features + tacticam_features\n",
    "        all_features_scaled = scaler.fit_transform(all_features)\n",
    "        broadcast_scaled = all_features_scaled[:len(broadcast_features)]\n",
    "        tacticam_scaled = all_features_scaled[len(broadcast_features):]\n",
    "        for i, b_feat in enumerate(broadcast_scaled):\n",
    "            for j, t_feat in enumerate(tacticam_scaled):\n",
    "                cos_sim = cosine_similarity([b_feat], [t_feat])[0, 0]\n",
    "                euclidean_dist = np.linalg.norm(b_feat - t_feat)\n",
    "                euclidean_sim = 1 / (1 + euclidean_dist)\n",
    "                if len(b_feat) > 1:\n",
    "                    correlation = np.corrcoef(b_feat, t_feat)[0, 1]\n",
    "                    correlation = 0 if np.isnan(correlation) else correlation\n",
    "                else:\n",
    "                    correlation = 0\n",
    "                combined_similarity = (0.5 * cos_sim + 0.3 * euclidean_sim + 0.2 * abs(correlation))\n",
    "                similarity_matrix[i, j] = max(0, min(1, combined_similarity))\n",
    "    noise = np.random.normal(0, 0.001, similarity_matrix.shape)\n",
    "    similarity_matrix = np.clip(similarity_matrix + noise, 0, 1)\n",
    "    return similarity_matrix\n",
    "\n",
    "def enhanced_player_mapping(broadcast_tracks, tacticam_tracks):\n",
    "    print(\"Computing enhanced features for all tracks...\")\n",
    "    broadcast_features = []\n",
    "    broadcast_classes = []\n",
    "    for i, track in enumerate(broadcast_tracks):\n",
    "        features = compute_enhanced_track_features(track, Config.BROADCAST_VIDEO)\n",
    "        broadcast_features.append(features)\n",
    "        broadcast_classes.append(track[0].get('class_name', 'unknown'))\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(broadcast_tracks)} broadcast tracks\")\n",
    "    tacticam_features = []\n",
    "    tacticam_classes = []\n",
    "    for i, track in enumerate(tacticam_tracks):\n",
    "        features = compute_enhanced_track_features(track, Config.TACTICAM_VIDEO)\n",
    "        tacticam_features.append(features)\n",
    "        tacticam_classes.append(track[0].get('class_name', 'unknown'))\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(tacticam_tracks)} tacticam tracks\")\n",
    "    print(\"Calculating similarity matrix...\")\n",
    "    similarity_matrix = calculate_similarity_matrix(broadcast_features, tacticam_features)\n",
    "    print(\"Applying class-based constraints...\")\n",
    "    for i, b_class in enumerate(broadcast_classes):\n",
    "        for j, t_class in enumerate(tacticam_classes):\n",
    "            if b_class != t_class:\n",
    "                similarity_matrix[i, j] = 0\n",
    "    print(\"Finding optimal assignment...\")\n",
    "    row_indices, col_indices = linear_sum_assignment(-similarity_matrix)\n",
    "    mappings = []\n",
    "    for row, col in zip(row_indices, col_indices):\n",
    "        similarity_score = similarity_matrix[row, col]\n",
    "        if similarity_score > 0.15:\n",
    "            mappings.append({\n",
    "                'broadcast_track_id': row,\n",
    "                'tacticam_track_id': col,\n",
    "                'similarity_score': similarity_score,\n",
    "                'player_class': broadcast_classes[row],\n",
    "                'broadcast_track_length': len(broadcast_tracks[row]),\n",
    "                'tacticam_track_length': len(tacticam_tracks[col])\n",
    "            })\n",
    "    return mappings, similarity_matrix\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RUNNING COMPLETE ENHANCED PLAYER MAPPING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Detecting players in broadcast video...\")\n",
    "broadcast_detections = process_video_detections(model, Config.BROADCAST_VIDEO, Config.FRAME_SKIP)\n",
    "print(\"Detecting players in tacticam video...\")\n",
    "tacticam_detections = process_video_detections(model, Config.TACTICAM_VIDEO, Config.FRAME_SKIP)\n",
    "print(\"Building tracks for broadcast video...\")\n",
    "broadcast_tracks = build_player_tracks(broadcast_detections)\n",
    "print(f\"Found {len(broadcast_tracks)} tracks in broadcast video\")\n",
    "print(\"Building tracks for tacticam video...\")\n",
    "tacticam_tracks = build_player_tracks(tacticam_detections)\n",
    "print(f\"Found {len(tacticam_tracks)} tracks in tacticam video\")\n",
    "print(\"Performing enhanced player mapping...\")\n",
    "player_mappings, similarity_matrix = enhanced_player_mapping(broadcast_tracks, tacticam_tracks)\n",
    "print(f\"\\nFound {len(player_mappings)} player mappings:\")\n",
    "for i, mapping in enumerate(player_mappings):\n",
    "    print(f\"Player {i+1}: {mapping['player_class']} - B{mapping['broadcast_track_id']} -> T{mapping['tacticam_track_id']} \"\n",
    "          f\"(similarity: {mapping['similarity_score']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c78e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RUNNING COMPLETE ENHANCED PLAYER MAPPING PIPELINE\n",
      "============================================================\n",
      "Detecting players in broadcast video...\n",
      "Processing data/broadcast.mp4...\n",
      "Processed 15 frames...\n",
      "Completed processing 27 frames, 304 total detections\n",
      "Detecting players in tacticam video...\n",
      "Processing data/tacticam.mp4...\n",
      "Processed 15 frames...\n",
      "Processed 30 frames...\n",
      "Completed processing 41 frames, 904 total detections\n",
      "Building tracks for broadcast video...\n",
      "Found 19 tracks in broadcast video\n",
      "Building tracks for tacticam video...\n",
      "Found 50 tracks in tacticam video\n",
      "Performing enhanced player mapping...\n",
      "Computing enhanced features for all tracks...\n",
      "Processed 5/19 broadcast tracks\n",
      "Processed 10/19 broadcast tracks\n",
      "Processed 15/19 broadcast tracks\n",
      "Processed 5/50 tacticam tracks\n",
      "Processed 10/50 tacticam tracks\n",
      "Processed 15/50 tacticam tracks\n",
      "Processed 20/50 tacticam tracks\n",
      "Processed 25/50 tacticam tracks\n",
      "Processed 30/50 tacticam tracks\n",
      "Processed 35/50 tacticam tracks\n",
      "Processed 40/50 tacticam tracks\n",
      "Processed 45/50 tacticam tracks\n",
      "Processed 50/50 tacticam tracks\n",
      "Calculating similarity matrix...\n",
      "Applying class-based constraints...\n",
      "Finding optimal assignment...\n",
      "\n",
      "Found 18 player mappings:\n",
      "Player 1: player - B0 -> T6 (similarity: 0.479)\n",
      "Player 2: player - B1 -> T9 (similarity: 0.542)\n",
      "Player 3: player - B2 -> T2 (similarity: 0.321)\n",
      "Player 4: player - B3 -> T8 (similarity: 0.152)\n",
      "Player 5: player - B4 -> T32 (similarity: 0.403)\n",
      "Player 6: player - B5 -> T7 (similarity: 0.173)\n",
      "Player 7: player - B6 -> T22 (similarity: 0.350)\n",
      "Player 8: player - B7 -> T19 (similarity: 0.283)\n",
      "Player 9: referee - B8 -> T21 (similarity: 0.251)\n",
      "Player 10: player - B9 -> T0 (similarity: 0.215)\n",
      "Player 11: referee - B10 -> T25 (similarity: 0.293)\n",
      "Player 12: goalkeeper - B11 -> T27 (similarity: 0.581)\n",
      "Player 13: referee - B12 -> T40 (similarity: 0.315)\n",
      "Player 14: referee - B13 -> T34 (similarity: 0.400)\n",
      "Player 15: player - B14 -> T42 (similarity: 0.330)\n",
      "Player 16: player - B15 -> T4 (similarity: 0.440)\n",
      "Player 17: player - B16 -> T3 (similarity: 0.227)\n",
      "Player 18: player - B17 -> T5 (similarity: 0.348)\n"
     ]
    }
   ],
   "source": [
    "# Performs enhanced multi-video soccer player mapping using visual, spatial, and temporal features\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def detect_soccer_players(model, frame, conf_threshold=0.3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    results = model(frame, conf=conf_threshold, device=device, verbose=False)\n",
    "    \n",
    "    detections = []\n",
    "    player_classes = [1, 2, 3]\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                confidence = box.conf[0].cpu().numpy()\n",
    "                class_id = int(box.cls[0].cpu().numpy())\n",
    "                if class_id in player_classes:\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    area = width * height\n",
    "                    if width > 10 and height > 20 and area > 300:\n",
    "                        detections.append({\n",
    "                            'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                            'confidence': float(confidence),\n",
    "                            'center': [(x1 + x2) / 2, (y1 + y2) / 2],\n",
    "                            'area': area,\n",
    "                            'class_id': class_id,\n",
    "                            'class_name': model.names[class_id],\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "    return detections\n",
    "\n",
    "def process_soccer_video(model, video_path, frame_skip=2, max_frames=200):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    detections_by_frame = {}\n",
    "    frame_idx = 0\n",
    "    processed_frames = 0\n",
    "    print(f\"Processing {video_path} for soccer players...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or processed_frames >= max_frames:\n",
    "            break\n",
    "        if frame_idx % frame_skip == 0:\n",
    "            detections = detect_soccer_players(model, frame, conf_threshold=0.3)\n",
    "            detections_by_frame[frame_idx] = detections\n",
    "            processed_frames += 1\n",
    "            if processed_frames % 20 == 0:\n",
    "                player_count = len(detections)\n",
    "                class_breakdown = {}\n",
    "                for det in detections:\n",
    "                    class_name = det['class_name']\n",
    "                    class_breakdown[class_name] = class_breakdown.get(class_name, 0) + 1\n",
    "                print(f\"Frame {frame_idx}: {player_count} total - {class_breakdown}\")\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    total_detections = sum(len(dets) for dets in detections_by_frame.values())\n",
    "    print(f\"Completed: {processed_frames} frames, {total_detections} total player detections\")\n",
    "    return detections_by_frame\n",
    "\n",
    "def extract_temporal_features(track):\n",
    "    if len(track) < 2:\n",
    "        return np.zeros(8)\n",
    "    positions = np.array([det['center'] for det in track])\n",
    "    frames = np.array([det['frame'] for det in track])\n",
    "    velocities = []\n",
    "    for i in range(1, len(positions)):\n",
    "        dx = positions[i][0] - positions[i-1][0]\n",
    "        dy = positions[i][1] - positions[i-1][1]\n",
    "        dt = frames[i] - frames[i-1]\n",
    "        if dt > 0:\n",
    "            vx = dx / dt\n",
    "            vy = dy / dt\n",
    "            velocities.append([vx, vy])\n",
    "    if not velocities:\n",
    "        return np.zeros(8)\n",
    "    velocities = np.array(velocities)\n",
    "    speed = np.sqrt(velocities[:, 0]**2 + velocities[:, 1]**2)\n",
    "    features = [\n",
    "        np.mean(speed),\n",
    "        np.max(speed),\n",
    "        np.var(speed),\n",
    "        np.mean(velocities[:, 0]),\n",
    "        np.mean(velocities[:, 1]),\n",
    "        frames[-1] - frames[0],\n",
    "        np.sqrt((positions[-1][0] - positions[0][0])**2 + (positions[-1][1] - positions[0][1])**2),\n",
    "        np.var(positions, axis=0).mean()\n",
    "    ]\n",
    "    return np.array(features)\n",
    "\n",
    "def compute_enhanced_track_features(track, video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    visual_features = []\n",
    "    spatial_features = []\n",
    "    for detection in track:\n",
    "        frame_idx = detection['frame']\n",
    "        bbox = detection['bbox']\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            vis_feat = extract_visual_features(frame, bbox)\n",
    "            visual_features.append(vis_feat)\n",
    "            spat_feat = extract_spatial_features(bbox, frame.shape)\n",
    "            spatial_features.append(spat_feat)\n",
    "    cap.release()\n",
    "    avg_visual = np.mean(visual_features, axis=0) if visual_features else np.zeros(Config.FEATURE_DIM)\n",
    "    avg_spatial = np.mean(spatial_features, axis=0) if spatial_features else np.zeros(6)\n",
    "    temporal_features = extract_temporal_features(track)\n",
    "    return np.concatenate([avg_visual, avg_spatial, temporal_features])\n",
    "\n",
    "def calculate_similarity_matrix(broadcast_features, tacticam_features):\n",
    "    similarity_matrix = np.zeros((len(broadcast_features), len(tacticam_features)))\n",
    "    scaler = StandardScaler()\n",
    "    if len(broadcast_features) > 0 and len(tacticam_features) > 0:\n",
    "        all_features = broadcast_features + tacticam_features\n",
    "        all_features_scaled = scaler.fit_transform(all_features)\n",
    "        broadcast_scaled = all_features_scaled[:len(broadcast_features)]\n",
    "        tacticam_scaled = all_features_scaled[len(broadcast_features):]\n",
    "        for i, b_feat in enumerate(broadcast_scaled):\n",
    "            for j, t_feat in enumerate(tacticam_scaled):\n",
    "                cos_sim = cosine_similarity([b_feat], [t_feat])[0, 0]\n",
    "                euclidean_dist = np.linalg.norm(b_feat - t_feat)\n",
    "                euclidean_sim = 1 / (1 + euclidean_dist)\n",
    "                if len(b_feat) > 1:\n",
    "                    correlation = np.corrcoef(b_feat, t_feat)[0, 1]\n",
    "                    correlation = 0 if np.isnan(correlation) else correlation\n",
    "                else:\n",
    "                    correlation = 0\n",
    "                combined_similarity = (0.5 * cos_sim + 0.3 * euclidean_sim + 0.2 * abs(correlation))\n",
    "                similarity_matrix[i, j] = max(0, min(1, combined_similarity))\n",
    "    noise = np.random.normal(0, 0.001, similarity_matrix.shape)\n",
    "    similarity_matrix = np.clip(similarity_matrix + noise, 0, 1)\n",
    "    return similarity_matrix\n",
    "\n",
    "def enhanced_player_mapping(broadcast_tracks, tacticam_tracks):\n",
    "    print(\"Computing enhanced features for all tracks...\")\n",
    "    broadcast_features = []\n",
    "    broadcast_classes = []\n",
    "    for i, track in enumerate(broadcast_tracks):\n",
    "        features = compute_enhanced_track_features(track, Config.BROADCAST_VIDEO)\n",
    "        broadcast_features.append(features)\n",
    "        broadcast_classes.append(track[0].get('class_name', 'unknown'))\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(broadcast_tracks)} broadcast tracks\")\n",
    "    tacticam_features = []\n",
    "    tacticam_classes = []\n",
    "    for i, track in enumerate(tacticam_tracks):\n",
    "        features = compute_enhanced_track_features(track, Config.TACTICAM_VIDEO)\n",
    "        tacticam_features.append(features)\n",
    "        tacticam_classes.append(track[0].get('class_name', 'unknown'))\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(tacticam_tracks)} tacticam tracks\")\n",
    "    print(\"Calculating similarity matrix...\")\n",
    "    similarity_matrix = calculate_similarity_matrix(broadcast_features, tacticam_features)\n",
    "    print(\"Applying class-based constraints...\")\n",
    "    for i, b_class in enumerate(broadcast_classes):\n",
    "        for j, t_class in enumerate(tacticam_classes):\n",
    "            if b_class != t_class:\n",
    "                similarity_matrix[i, j] = 0\n",
    "    print(\"Finding optimal assignment...\")\n",
    "    row_indices, col_indices = linear_sum_assignment(-similarity_matrix)\n",
    "    mappings = []\n",
    "    for row, col in zip(row_indices, col_indices):\n",
    "        similarity_score = similarity_matrix[row, col]\n",
    "        if similarity_score > 0.15:\n",
    "            mappings.append({\n",
    "                'broadcast_track_id': row,\n",
    "                'tacticam_track_id': col,\n",
    "                'similarity_score': similarity_score,\n",
    "                'player_class': broadcast_classes[row],\n",
    "                'broadcast_track_length': len(broadcast_tracks[row]),\n",
    "                'tacticam_track_length': len(tacticam_tracks[col])\n",
    "            })\n",
    "    return mappings, similarity_matrix\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RUNNING COMPLETE ENHANCED PLAYER MAPPING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Detecting players in broadcast video...\")\n",
    "broadcast_detections = process_video_detections(model, Config.BROADCAST_VIDEO, Config.FRAME_SKIP)\n",
    "print(\"Detecting players in tacticam video...\")\n",
    "tacticam_detections = process_video_detections(model, Config.TACTICAM_VIDEO, Config.FRAME_SKIP)\n",
    "print(\"Building tracks for broadcast video...\")\n",
    "broadcast_tracks = build_player_tracks(broadcast_detections)\n",
    "print(f\"Found {len(broadcast_tracks)} tracks in broadcast video\")\n",
    "print(\"Building tracks for tacticam video...\")\n",
    "tacticam_tracks = build_player_tracks(tacticam_detections)\n",
    "print(f\"Found {len(tacticam_tracks)} tracks in tacticam video\")\n",
    "print(\"Performing enhanced player mapping...\")\n",
    "player_mappings, similarity_matrix = enhanced_player_mapping(broadcast_tracks, tacticam_tracks)\n",
    "print(f\"\\nFound {len(player_mappings)} player mappings:\")\n",
    "for i, mapping in enumerate(player_mappings):\n",
    "    print(f\"Player {i+1}: {mapping['player_class']} - B{mapping['broadcast_track_id']} -> T{mapping['tacticam_track_id']} \"\n",
    "          f\"(similarity: {mapping['similarity_score']:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8be272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates frame-by-frame labeled data for matched and unmatched player tracks\n",
    "def create_frame_by_frame_data(broadcast_tracks, tacticam_tracks, mappings):\n",
    "    track_to_player = {}\n",
    "    for i, mapping in enumerate(mappings):\n",
    "        player_id = f\"player_{i+1:02d}\"\n",
    "        track_to_player[('broadcast', mapping['broadcast_track_id'])] = player_id\n",
    "        track_to_player[('tacticam', mapping['tacticam_track_id'])] = player_id\n",
    "\n",
    "    csv_data = []\n",
    "\n",
    "    for track_idx, track in enumerate(broadcast_tracks):\n",
    "        player_id = track_to_player.get(('broadcast', track_idx), f\"unmatched_b_{track_idx}\")\n",
    "        for detection in track:\n",
    "            csv_data.append({\n",
    "                'frame': detection['frame'],\n",
    "                'camera': 'broadcast',\n",
    "                'player_id': player_id,\n",
    "                'bbox_x1': detection['bbox'][0],\n",
    "                'bbox_y1': detection['bbox'][1],\n",
    "                'bbox_x2': detection['bbox'][2],\n",
    "                'bbox_y2': detection['bbox'][3],\n",
    "                'center_x': detection['center'][0],\n",
    "                'center_y': detection['center'][1],\n",
    "                'confidence': detection['confidence'],\n",
    "                'class': detection.get('class_name', 'unknown')\n",
    "            })\n",
    "\n",
    "    for track_idx, track in enumerate(tacticam_tracks):\n",
    "        player_id = track_to_player.get(('tacticam', track_idx), f\"unmatched_t_{track_idx}\")\n",
    "        for detection in track:\n",
    "            csv_data.append({\n",
    "                'frame': detection['frame'],\n",
    "                'camera': 'tacticam',\n",
    "                'player_id': player_id,\n",
    "                'bbox_x1': detection['bbox'][0],\n",
    "                'bbox_y1': detection['bbox'][1],\n",
    "                'bbox_x2': detection['bbox'][2],\n",
    "                'bbox_y2': detection['bbox'][3],\n",
    "                'center_x': detection['center'][0],\n",
    "                'center_y': detection['center'][1],\n",
    "                'confidence': detection['confidence'],\n",
    "                'class': detection.get('class_name', 'unknown')\n",
    "            })\n",
    "\n",
    "    return csv_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d66343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Optimized Pipeline with GPU Acceleration and Improved Similarity\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ RUNNING FINAL OPTIMIZED GPU-ACCELERATED PIPELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Re-run with GPU optimizations and better parameters\n",
    "print(\"üîÑ Re-processing with GPU acceleration...\")\n",
    "\n",
    "# Enhanced configuration for better results\n",
    "Config.CONFIDENCE_THRESHOLD = 0.25  # Lower threshold for more detections\n",
    "Config.FRAME_SKIP = 3  # Process more frames\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úÖ GPU cache cleared\")\n",
    "\n",
    "# Re-detect with GPU acceleration\n",
    "print(\"üîç GPU-accelerated detection on broadcast video...\")\n",
    "broadcast_detections_gpu = process_video_detections(model, Config.BROADCAST_VIDEO, Config.FRAME_SKIP, max_frames=150)\n",
    "\n",
    "print(\"üîç GPU-accelerated detection on tacticam video...\")\n",
    "tacticam_detections_gpu = process_video_detections(model, Config.TACTICAM_VIDEO, Config.FRAME_SKIP, max_frames=150)\n",
    "\n",
    "# Build improved tracks with better parameters\n",
    "print(\"üîó Building improved tracks...\")\n",
    "broadcast_tracks_gpu = build_player_tracks(broadcast_detections_gpu, max_distance=60, max_frame_gap=8, min_track_length=2)\n",
    "tacticam_tracks_gpu = build_player_tracks(tacticam_detections_gpu, max_distance=60, max_frame_gap=8, min_track_length=2)\n",
    "\n",
    "print(f\"üìä GPU Results:\")\n",
    "print(f\"   Broadcast tracks: {len(broadcast_tracks_gpu)}\")\n",
    "print(f\"   Tacticam tracks: {len(tacticam_tracks_gpu)}\")\n",
    "\n",
    "# Enhanced mapping with improved similarity calculation\n",
    "print(\"üéØ Running enhanced mapping with improved similarity...\")\n",
    "player_mappings_gpu, similarity_matrix_gpu = enhanced_player_mapping(broadcast_tracks_gpu, tacticam_tracks_gpu)\n",
    "\n",
    "print(f\"\\n‚úÖ GPU-Optimized Results:\")\n",
    "print(f\"   üéØ Player mappings: {len(player_mappings_gpu)}\")\n",
    "print(f\"   üìä Similarity matrix shape: {similarity_matrix_gpu.shape}\")\n",
    "print(f\"   üî¢ Similarity range: {similarity_matrix_gpu.min():.3f} - {similarity_matrix_gpu.max():.3f}\")\n",
    "\n",
    "# Check for improvement in zero values\n",
    "zero_count_gpu = np.sum(similarity_matrix_gpu < 0.01)\n",
    "total_values_gpu = similarity_matrix_gpu.size\n",
    "zero_percentage_gpu = (zero_count_gpu / total_values_gpu) * 100\n",
    "\n",
    "print(f\"   üéØ Zero/near-zero values: {zero_count_gpu}/{total_values_gpu} ({zero_percentage_gpu:.1f}%)\")\n",
    "\n",
    "# Generate final outputs with GPU-optimized data\n",
    "print(\"\\nüì¶ Generating final GPU-optimized outputs...\")\n",
    "csv_data_gpu = create_frame_by_frame_data(broadcast_tracks_gpu, tacticam_tracks_gpu, player_mappings_gpu)\n",
    "df_gpu = pd.DataFrame(csv_data_gpu)\n",
    "df_gpu.to_csv(Config.OUTPUT_DIR / 'gpu_optimized_tracking_results.csv', index=False)\n",
    "\n",
    "# Final visualization\n",
    "plt.figure(figsize=(12, 10))\n",
    "viz_matrix_gpu = similarity_matrix_gpu[:min(20, similarity_matrix_gpu.shape[0]), :min(20, similarity_matrix_gpu.shape[1])]\n",
    "\n",
    "sns.heatmap(viz_matrix_gpu, \n",
    "            annot=True, \n",
    "            fmt='.2f', \n",
    "            cmap='RdYlGn',\n",
    "            center=0.5,     \n",
    "            vmin=0,         \n",
    "            vmax=1,         \n",
    "            square=True,    \n",
    "            linewidths=0.5)\n",
    "\n",
    "plt.title('üöÄ GPU-Optimized Player Similarity Matrix\\n(Enhanced Features + CUDA Acceleration)', fontsize=14, pad=20)\n",
    "plt.xlabel('Tacticam Tracks', fontsize=12)\n",
    "plt.ylabel('Broadcast Tracks', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.OUTPUT_DIR / 'gpu_optimized_similarity_matrix.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéâ GPU-OPTIMIZED PIPELINE COMPLETE!\")\n",
    "print(f\"‚úÖ Files generated:\")\n",
    "print(f\"   üìÑ outputs/gpu_optimized_tracking_results.csv\")\n",
    "print(f\"   üìä outputs/gpu_optimized_similarity_matrix.png\")\n",
    "\n",
    "# Memory cleanup\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nüíæ Final GPU Memory Usage:\")\n",
    "    print(f\"   Allocated: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n",
    "    print(f\"   Cached: {torch.cuda.memory_reserved()/1024**2:.1f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
